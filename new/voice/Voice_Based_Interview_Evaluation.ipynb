{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "z8CdY0o9MgWf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Separating only student audio files from segmented audio based on time stamps"
      ],
      "metadata": {
        "id": "z8CdY0o9MgWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define source and destination directories\n",
        "dir1 = '/content/drive/MyDrive/Jyothi Mam/second/temp'\n",
        "dir2 = '/content/drive/MyDrive/Jyothi Mam/second/student_audios'\n",
        "\n",
        "# Ensure the destination directory exists\n",
        "os.makedirs(dir2, exist_ok=True)\n",
        "\n",
        "# List all files in the source directory\n",
        "files = os.listdir(dir1)\n",
        "\n",
        "# Filter and move files based on the pattern\n",
        "for file in files:\n",
        "    if file.startswith('SPEAKER_00'):\n",
        "        # Define full file path\n",
        "        source_file = os.path.join(dir1, file)\n",
        "        destination_file = os.path.join(dir2, file)\n",
        "        # Move the file\n",
        "        shutil.move(source_file, destination_file)\n",
        "        print(f\"Moved: {file}\")\n",
        "\n",
        "print(\"File transfer completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGnuoHVFLEAw",
        "outputId": "a3389064-8dbc-4e82-995b-87810363415a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File transfer completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM-Based Emotion Recognition and Grading System with MFCC Feature Extraction"
      ],
      "metadata": {
        "id": "YQbIA2F-JIU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2s-evwZNubQ",
        "outputId": "5a396b69-471d-427f-f6fe-493f23e17309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dir2 = '/content/drive/MyDrive/Jyothi Mam/second/student_audios'\n",
        "files = os.listdir(dir2)\n",
        "new_paths = [os.path.join(dir2, file) for file in files]\n",
        "print(new_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtEmq5UWTvKv",
        "outputId": "9d7a9059-132c-430b-d60d-d7a4d9a11cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_2.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_4.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_6.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_8.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_10.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_12.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_14.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_16.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_18.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_20.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_22.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_24.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_26.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_28.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_30.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_32.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_34.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_36.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_38.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_40.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_42.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_44.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_46.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_48.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_50.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_52.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_54.wav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/Jyothi Mam/second/my_model.h5')\n",
        "\n",
        "def extract_mfcc(filename):\n",
        "    y, sr = librosa.load(filename, duration=3, offset=0.5)\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
        "    return mfcc\n",
        "\n",
        "def preprocess_new_data(paths):\n",
        "    new_mfccs = []\n",
        "    for path in paths:\n",
        "        mfcc = extract_mfcc(path)\n",
        "        new_mfccs.append(mfcc)\n",
        "    new_mfccs = np.array(new_mfccs)\n",
        "    new_mfccs = np.expand_dims(new_mfccs, -1)\n",
        "    return new_mfccs\n",
        "\n",
        "labels = ['fear', 'angry', 'disgust', 'neutral', 'sad', 'ps', 'happy']\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(np.array(labels).reshape(-1, 1))\n",
        "new_X = preprocess_new_data(new_paths)\n",
        "predictions = model.predict(new_X)\n",
        "predicted_labels = enc.inverse_transform(predictions)\n",
        "for i, label in enumerate(predicted_labels):\n",
        "    print(f\"File: {new_paths[i]} - Predicted Label: {label[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFff009cUhgH",
        "outputId": "9312e3aa-39e6-4a65-eb2c-a5a4220ebbe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_2.wav - Predicted Label: happy\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_4.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_6.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_8.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_10.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_12.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_14.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_16.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_18.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_20.wav - Predicted Label: disgust\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_22.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_24.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_26.wav - Predicted Label: disgust\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_28.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_30.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_32.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_34.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_36.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_38.wav - Predicted Label: disgust\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_40.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_42.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_44.wav - Predicted Label: disgust\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_46.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_48.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_50.wav - Predicted Label: disgust\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_52.wav - Predicted Label: fear\n",
            "File: /content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_54.wav - Predicted Label: fear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_grade(predicted_labels):\n",
        "    emotion_weights = {\n",
        "        'fear': 10,\n",
        "        'angry': 5,\n",
        "        'disgust': 5,\n",
        "        'neutral': 15,\n",
        "        'sad': 10,\n",
        "        'ps': 25,\n",
        "        'happy': 20\n",
        "    }\n",
        "    total_score = 0\n",
        "    for label in predicted_labels:\n",
        "        emotion = label[0]\n",
        "        if emotion in emotion_weights:\n",
        "            total_score += emotion_weights[emotion]\n",
        "\n",
        "    # Normalize the score\n",
        "    max_possible_score = len(predicted_labels) * max(emotion_weights.values())\n",
        "    normalized_score = (total_score / max_possible_score) * 100\n",
        "\n",
        "    # Ensure the score is at least 1\n",
        "    normalized_score = max(1, normalized_score)\n",
        "\n",
        "    return round(normalized_score, 2)\n",
        "\n",
        "# Calculate the grade\n",
        "student_grade = calculate_grade(predicted_labels)\n",
        "\n",
        "print(f\"Student's Interview Grade: {student_grade:.2f} / 100\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCPlAr4QZ6NT",
        "outputId": "a76cff35-5dcd-4f55-cb12-2ca924c49acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student's Interview Grade: 37.86 / 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modulation Analysis\n",
        "\n",
        "### Analyzes an audio signal to calculate a modulation score by evaluating pitch variations, volume variations, and tone variations using the librosa library.\n",
        "\n",
        "- Higher pitch variation indicates more fluctuation in pitch, which might suggest expressive or dynamic speech. Lower variation suggests more monotonic or stable pitch.\n",
        "- Higher volume variation indicates changes in loudness, suggesting dynamic or expressive speech. Lower variation suggests more consistent or even volume.\n",
        "- Higher tone variation suggests more dynamic or varied tonal quality in the speech, while lower variation suggests more consistent tonal quality.\n",
        "- Lower modulation scores (closer to 0) indicate more monotonic and consistent speech, with little variation in pitch, volume, and tone.\n",
        "- Higher modulation scores (200-350 in your case) indicate more dynamic, varied, and possibly more engaging speech, with significant changes in pitch, volume, and tone.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jC4o3FckE-kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def analyze_modulation(y, sr):\n",
        "    # Pitch analysis\n",
        "    pitches, _ = librosa.piptrack(y=y, sr=sr)\n",
        "    pitch_variations = np.std(pitches[pitches > 0])\n",
        "\n",
        "    # Volume analysis\n",
        "    rms = librosa.feature.rms(y=y)[0]\n",
        "    volume_variations = np.std(rms)\n",
        "\n",
        "    # Spectral contrast for tone\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1)\n",
        "    tone_variations = np.std(contrast)\n",
        "\n",
        "    # Combine into a single score\n",
        "    modulation_score = (pitch_variations + volume_variations + tone_variations) / 3\n",
        "\n",
        "    return modulation_score"
      ],
      "metadata": {
        "id": "Pn8lIfcWEgl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_audio_files(paths):\n",
        "    scores = {}\n",
        "    for path in paths:\n",
        "        if path.lower().endswith('.wav'):\n",
        "            y, sr = librosa.load(path, sr=None)\n",
        "            score = analyze_modulation(y, sr)\n",
        "            filename = os.path.basename(path)\n",
        "            scores[filename] = score\n",
        "    return scores\n",
        "\n",
        "# Directory containing your audio files\n",
        "dir2 = '/content/drive/MyDrive/Jyothi Mam/second/student_audios'\n",
        "files = os.listdir(dir2)\n",
        "new_paths = [os.path.join(dir2, file) for file in files]\n",
        "print(new_paths)\n",
        "\n",
        "# Analyze the audio files and get modulation scores\n",
        "modulation_scores = analyze_audio_files(new_paths)\n",
        "\n",
        "# Print the results\n",
        "for filename, score in modulation_scores.items():\n",
        "    print(f\"File: {filename} - Modulation Score: {score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLqn3vle5Gqy",
        "outputId": "b619e192-9043-4439-f088-a4ad06736c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_2.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_4.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_6.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_8.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_10.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_12.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_14.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_16.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_18.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_20.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_22.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_24.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_26.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_28.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_30.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_32.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_34.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_36.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_38.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_40.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_42.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_44.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_46.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_48.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_50.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_52.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_54.wav']\n",
            "File: SPEAKER_00.wav - Modulation Score: 253.33\n",
            "File: SPEAKER_00_2.wav - Modulation Score: 291.83\n",
            "File: SPEAKER_00_4.wav - Modulation Score: 239.18\n",
            "File: SPEAKER_00_6.wav - Modulation Score: 266.94\n",
            "File: SPEAKER_00_8.wav - Modulation Score: 318.32\n",
            "File: SPEAKER_00_10.wav - Modulation Score: 279.05\n",
            "File: SPEAKER_00_12.wav - Modulation Score: 291.29\n",
            "File: SPEAKER_00_14.wav - Modulation Score: 215.77\n",
            "File: SPEAKER_00_16.wav - Modulation Score: 276.86\n",
            "File: SPEAKER_00_18.wav - Modulation Score: 272.87\n",
            "File: SPEAKER_00_20.wav - Modulation Score: 290.41\n",
            "File: SPEAKER_00_22.wav - Modulation Score: 207.86\n",
            "File: SPEAKER_00_24.wav - Modulation Score: 313.23\n",
            "File: SPEAKER_00_26.wav - Modulation Score: 276.10\n",
            "File: SPEAKER_00_28.wav - Modulation Score: 286.79\n",
            "File: SPEAKER_00_30.wav - Modulation Score: 242.15\n",
            "File: SPEAKER_00_32.wav - Modulation Score: 278.49\n",
            "File: SPEAKER_00_34.wav - Modulation Score: 326.53\n",
            "File: SPEAKER_00_36.wav - Modulation Score: 270.17\n",
            "File: SPEAKER_00_38.wav - Modulation Score: 240.50\n",
            "File: SPEAKER_00_40.wav - Modulation Score: 178.40\n",
            "File: SPEAKER_00_42.wav - Modulation Score: 259.04\n",
            "File: SPEAKER_00_44.wav - Modulation Score: 302.51\n",
            "File: SPEAKER_00_46.wav - Modulation Score: 237.93\n",
            "File: SPEAKER_00_48.wav - Modulation Score: 246.34\n",
            "File: SPEAKER_00_50.wav - Modulation Score: 230.25\n",
            "File: SPEAKER_00_52.wav - Modulation Score: 229.79\n",
            "File: SPEAKER_00_54.wav - Modulation Score: 253.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confidence Assessment\n",
        "### Assesses the confidence level in speech by analyzing the speech rate, pause ratio, and pitch stability of an audio signal, then combines these factors into a single confidence score using the librosa library.\n",
        "\n",
        "-  A higher speech rate (faster tempo) is generally associated with higher confidence, as confident speakers tend to speak more fluently and quickly.\n",
        "- A lower pause ratio (i.e., more continuous speech with fewer pauses) is often associated with higher confidence, as confident speakers tend to have fewer hesitations.\n",
        "- Higher pitch stability (lower variation) suggests a more consistent and steady voice, which can be a sign of confidence. A shaky or highly variable pitch might indicate nervousness.\n",
        "- Scores closer to 1 suggest a highly confident speaker.\n",
        "- Scores closer to 0 suggest a less confident or more hesitant speaker.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3Cigc8vJJyXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assess_confidence(y, sr):\n",
        "    # Speech rate\n",
        "    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n",
        "    tempo, _ = librosa.beat.beat_track(onset_envelope=onset_env, sr=sr)\n",
        "\n",
        "    # Pauses\n",
        "    non_silent_intervals = librosa.effects.split(y, top_db=20)\n",
        "    total_duration = len(y) / sr\n",
        "    speech_duration = sum(interval[1] - interval[0] for interval in non_silent_intervals) / sr\n",
        "    pause_ratio = 1 - (speech_duration / total_duration)\n",
        "\n",
        "    # Pitch stability\n",
        "    pitches, _ = librosa.piptrack(y=y, sr=sr)\n",
        "    pitch_stability = 1 / (np.std(pitches[pitches > 0]) + 1)\n",
        "\n",
        "    # Combine factors\n",
        "    confidence_score = (tempo / 120 + (1 - pause_ratio) + pitch_stability) / 3\n",
        "\n",
        "    return confidence_score"
      ],
      "metadata": {
        "id": "RiiRSAzXElIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_confidence_scores(paths):\n",
        "    scores = {}\n",
        "\n",
        "    for path in paths:\n",
        "        if path.lower().endswith('.wav'):\n",
        "            y, sr = librosa.load(path, sr=None)\n",
        "            score = assess_confidence(y, sr)\n",
        "            filename = os.path.basename(path)\n",
        "            scores[filename] = score[0]\n",
        "    return scores\n",
        "\n",
        "# Directory containing your audio files\n",
        "dir2 = '/content/drive/MyDrive/Jyothi Mam/second/student_audios'\n",
        "files = os.listdir(dir2)\n",
        "new_paths = [os.path.join(dir2, file) for file in files]\n",
        "print(new_paths)\n",
        "\n",
        "# Analyze the audio files and get confidence scores\n",
        "confidence_scores = analyze_confidence_scores(new_paths)\n",
        "\n",
        "# Print the results\n",
        "for filename, score in confidence_scores.items():\n",
        "    print(f\"File: {filename} - Confidence Score: {score:.2f}\")\n"
      ],
      "metadata": {
        "id": "682qPUUW7IPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b03c722-0e50-47f7-c52a-6496a4ffe78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_2.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_4.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_6.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_8.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_10.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_12.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_14.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_16.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_18.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_20.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_22.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_24.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_26.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_28.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_30.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_32.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_34.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_36.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_38.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_40.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_42.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_44.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_46.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_48.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_50.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_52.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_54.wav']\n",
            "File: SPEAKER_00.wav - Confidence Score: 0.65\n",
            "File: SPEAKER_00_2.wav - Confidence Score: 0.62\n",
            "File: SPEAKER_00_4.wav - Confidence Score: 0.64\n",
            "File: SPEAKER_00_6.wav - Confidence Score: 0.66\n",
            "File: SPEAKER_00_8.wav - Confidence Score: 0.68\n",
            "File: SPEAKER_00_10.wav - Confidence Score: 0.60\n",
            "File: SPEAKER_00_12.wav - Confidence Score: 0.60\n",
            "File: SPEAKER_00_14.wav - Confidence Score: 0.60\n",
            "File: SPEAKER_00_16.wav - Confidence Score: 0.61\n",
            "File: SPEAKER_00_18.wav - Confidence Score: 0.69\n",
            "File: SPEAKER_00_20.wav - Confidence Score: 0.72\n",
            "File: SPEAKER_00_22.wav - Confidence Score: 0.69\n",
            "File: SPEAKER_00_24.wav - Confidence Score: 0.65\n",
            "File: SPEAKER_00_26.wav - Confidence Score: 0.56\n",
            "File: SPEAKER_00_28.wav - Confidence Score: 0.61\n",
            "File: SPEAKER_00_30.wav - Confidence Score: 0.68\n",
            "File: SPEAKER_00_32.wav - Confidence Score: 0.62\n",
            "File: SPEAKER_00_34.wav - Confidence Score: 0.63\n",
            "File: SPEAKER_00_36.wav - Confidence Score: 0.69\n",
            "File: SPEAKER_00_38.wav - Confidence Score: 0.61\n",
            "File: SPEAKER_00_40.wav - Confidence Score: 0.69\n",
            "File: SPEAKER_00_42.wav - Confidence Score: 0.66\n",
            "File: SPEAKER_00_44.wav - Confidence Score: 0.58\n",
            "File: SPEAKER_00_46.wav - Confidence Score: 0.67\n",
            "File: SPEAKER_00_48.wav - Confidence Score: 0.63\n",
            "File: SPEAKER_00_50.wav - Confidence Score: 0.62\n",
            "File: SPEAKER_00_52.wav - Confidence Score: 0.66\n",
            "File: SPEAKER_00_54.wav - Confidence Score: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filler Words Detection\n",
        "##### This code detects filler words in an audio file by converting the speech to text using Google's speech recognition service and then calculating the ratio of filler words (like \"um\" and \"uh\") to the total word count. If speech recognition fails, it returns 0.\n",
        "\n",
        "- A value close to 0 indicates fewer filler words relative to the total number of words, while a value close to 1 indicates a higher proportion of filler words"
      ],
      "metadata": {
        "id": "jXUPiuISKOF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "id": "e6iquQYxEqpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d7987d-f63f-4742-dac2-386f1bec3550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.10.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "def detect_filler_words(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)\n",
        "\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        filler_words = ['um', 'uh', 'like', 'you know', 'so', 'Basically', 'Actually', 'Just', 'Really']\n",
        "        filler_count = sum(text.lower().count(word) for word in filler_words)\n",
        "        word_count = len(text.split())\n",
        "        filler_ratio = filler_count / word_count if word_count > 0 else 0\n",
        "        return filler_ratio\n",
        "    except:\n",
        "        return 0  # Return 0 if speech recognition fails"
      ],
      "metadata": {
        "id": "0wqjIpVKEte0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_filler_word_scores(paths):\n",
        "    scores = {}\n",
        "    for path in paths:\n",
        "        if path.lower().endswith('.wav'):\n",
        "            score = detect_filler_words(path)\n",
        "            filename = os.path.basename(path)\n",
        "            scores[filename] = score\n",
        "    return scores\n",
        "\n",
        "# Directory containing your audio files\n",
        "dir2 = '/content/drive/MyDrive/Jyothi Mam/second/student_audios'\n",
        "files = os.listdir(dir2)\n",
        "new_paths = [os.path.join(dir2, file) for file in files]\n",
        "print(new_paths)\n",
        "\n",
        "# Analyze the audio files and get filler word scores\n",
        "filler_word_scores = analyze_filler_word_scores(new_paths)\n",
        "\n",
        "# Print the results\n",
        "for filename, score in filler_word_scores.items():\n",
        "    print(f\"File: {filename} - Filler Word Ratio: {score:.2f}\")\n"
      ],
      "metadata": {
        "id": "3FnvDnJE8GUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa0da6c-b742-4eb0-e05c-b0a17ca35332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_2.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_4.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_6.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_8.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_10.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_12.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_14.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_16.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_18.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_20.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_22.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_24.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_26.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_28.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_30.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_32.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_34.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_36.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_38.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_40.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_42.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_44.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_46.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_48.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_50.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_52.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_54.wav']\n",
            "File: SPEAKER_00.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_2.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_4.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_6.wav - Filler Word Ratio: 0.20\n",
            "File: SPEAKER_00_8.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_10.wav - Filler Word Ratio: 0.09\n",
            "File: SPEAKER_00_12.wav - Filler Word Ratio: 0.10\n",
            "File: SPEAKER_00_14.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_16.wav - Filler Word Ratio: 0.08\n",
            "File: SPEAKER_00_18.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_20.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_22.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_24.wav - Filler Word Ratio: 0.03\n",
            "File: SPEAKER_00_26.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_28.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_30.wav - Filler Word Ratio: 0.33\n",
            "File: SPEAKER_00_32.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_34.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_36.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_38.wav - Filler Word Ratio: 0.04\n",
            "File: SPEAKER_00_40.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_42.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_44.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_46.wav - Filler Word Ratio: 0.10\n",
            "File: SPEAKER_00_48.wav - Filler Word Ratio: 0.20\n",
            "File: SPEAKER_00_50.wav - Filler Word Ratio: 0.25\n",
            "File: SPEAKER_00_52.wav - Filler Word Ratio: 0.00\n",
            "File: SPEAKER_00_54.wav - Filler Word Ratio: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Total Evaluation\n",
        "#### This code evaluates interview performance by analyzing different audio segments. It calculates an overall interview score for each segment based on modulation, confidence, and filler word usage, then computes the final score as the average of all segment scores. The final interview score is printed on a scale of 0 to 100."
      ],
      "metadata": {
        "id": "zb6--IjDKwn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "dir2 = '/content/drive/MyDrive/Jyothi Mam/second/student_audios'\n",
        "f1 = os.listdir(dir2)\n",
        "student_segments = []\n",
        "for i in f1:\n",
        "  file_path=os.path.join(dir2,i)\n",
        "  student_segments.append(file_path)\n",
        "print(student_segments)\n",
        "print(len(student_segments))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjRgK9hiMsr5",
        "outputId": "fc8a99a5-9ac9-4a24-b3ba-ebaad662be8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_2.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_4.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_6.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_8.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_10.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_12.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_14.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_16.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_18.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_20.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_22.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_24.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_26.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_28.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_30.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_32.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_34.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_36.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_38.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_40.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_42.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_44.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_46.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_48.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_50.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_52.wav', '/content/drive/MyDrive/Jyothi Mam/second/student_audios/SPEAKER_00_54.wav']\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def assess_interview(audio_file):\n",
        "    y, sr = librosa.load(audio_file)\n",
        "\n",
        "    modulation_score = analyze_modulation(y, sr)\n",
        "    confidence_score = assess_confidence(y, sr)\n",
        "    filler_ratio = detect_filler_words(audio_file)\n",
        "    grade_score = calculate_grade(predicted_labels)\n",
        "\n",
        "    # Normalize scores\n",
        "    modulation_norm = np.clip(modulation_score / 350, 0, 1)  # Normalized to a scale of 0-1\n",
        "    confidence_norm = np.clip(confidence_score, 0, 1)    # Normalized to a scale of 0-1\n",
        "    filler_norm = 1 - np.clip(filler_ratio, 0, 1)            # Invert so that lower filler word usage is better\n",
        "\n",
        "    # Combine scores (adjust weights as needed)\n",
        "    overall_score = (modulation_norm * 0.25 + confidence_norm * 0.35 + filler_norm * 0.20 + grade_score /100 * 0.20) * 100\n",
        "\n",
        "    return overall_score\n",
        "\n",
        "# Assess each segment\n",
        "segment_scores = [assess_interview(segment) for segment in student_segments]\n",
        "\n",
        "# Calculate final score\n",
        "final_score = np.mean(segment_scores)\n",
        "\n",
        "# Print final score\n",
        "print(f\"Final Interview Score: {final_score:.2f}\")"
      ],
      "metadata": {
        "id": "HKhDwlx3Ev4B",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0bf9f25-955a-4c8d-b8ef-934298ab7fc9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Interview Score: 67.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### This code generates a detailed report of an interview assessment, including the overall score, scores for individual segments, and areas for improvement based on the final score and segment scores. It provides specific recommendations for improving interview skills, consistency, and confidence based on the scores."
      ],
      "metadata": {
        "id": "t_ybI1uXLSPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_report(final_score, segment_scores):\n",
        "    report = f\"Interview Assessment Report\\n\"\n",
        "    report += f\"Overall Score: {final_score:.2f}/100\\n\\n\"\n",
        "    report += f\"Segment Scores:\\n\"\n",
        "    for i, score in enumerate(segment_scores):\n",
        "        score_value = float(score)  # Convert to float (or use score.item())\n",
        "        report += f\"Segment {i+1}: {score_value:.2f}/100\\n\"\n",
        "\n",
        "    # report += \"\\nAreas for Improvement:\\n\"\n",
        "    # if final_score < 60:\n",
        "    #     report += \"- Work on overall interview skills, including voice modulation and confidence\\n\"\n",
        "    # if min(segment_scores) < final_score - 10:\n",
        "    #     report += \"- Aim for more consistent performance across all responses\\n\"\n",
        "    # if final_score < 70:\n",
        "    #     report += \"- Practice reducing filler words and speaking more confidently\\n\"\n",
        "\n",
        "    return report\n",
        "\n",
        "\n",
        "# Print final report\n",
        "print(generate_report(final_score, segment_scores))\n"
      ],
      "metadata": {
        "id": "8BPmZrwiEwzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00390084-1cfa-43fb-9f7e-2bc8a97991a0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interview Assessment Report\n",
            "Overall Score: 67.23/100\n",
            "\n",
            "Segment Scores:\n",
            "Segment 1: 68.04/100\n",
            "Segment 2: 68.53/100\n",
            "Segment 3: 66.57/100\n",
            "Segment 4: 64.43/100\n",
            "Segment 5: 73.38/100\n",
            "Segment 6: 67.01/100\n",
            "Segment 7: 69.21/100\n",
            "Segment 8: 62.66/100\n",
            "Segment 9: 66.89/100\n",
            "Segment 10: 70.12/100\n",
            "Segment 11: 70.03/100\n",
            "Segment 12: 65.14/100\n",
            "Segment 13: 71.70/100\n",
            "Segment 14: 67.06/100\n",
            "Segment 15: 68.98/100\n",
            "Segment 16: 61.24/100\n",
            "Segment 17: 68.13/100\n",
            "Segment 18: 74.53/100\n",
            "Segment 19: 70.58/100\n",
            "Segment 20: 64.30/100\n",
            "Segment 21: 63.69/100\n",
            "Segment 22: 66.97/100\n",
            "Segment 23: 69.87/100\n",
            "Segment 24: 65.09/100\n",
            "Segment 25: 62.30/100\n",
            "Segment 26: 59.02/100\n",
            "Segment 27: 68.84/100\n",
            "Segment 28: 68.04/100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-f85b10e026ae>:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  score_value = float(score)  # Convert to float (or use score.item())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9dPPkv4Geub"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}